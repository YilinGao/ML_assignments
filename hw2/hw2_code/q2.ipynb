{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compsci 571 Homework 2\n",
    "Question 2 Variable Importance in Trees and Random Forests\n",
    "Yilin Gao (yg95)\n",
    "Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n",
      "(100, 6)\n"
     ]
    }
   ],
   "source": [
    "train = np.genfromtxt('train.csv', delimiter=',', skip_header=1)\n",
    "test = np.genfromtxt('test.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "train_X = train[:, 0: -1]\n",
    "train_y = train[:, -1]\n",
    "\n",
    "test_X = test[:, 0: -1]\n",
    "test_y = test[:, -1]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2a1, decision stump based on the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a tree node on variable X[split] and threshold = thre into 2 child nodes\n",
    "# parameter X: the feature matrix, shape = [n, p]\n",
    "# parameter y: the label vector, shape = [n, 1]\n",
    "# parameter split: the index for the splitting variable in the feature matrix, in [0, p)\n",
    "# parameter thre: the splitting threshold for the splitting variable\n",
    "# parameter y0: the actual value of one type of label\n",
    "# parameter y1: the actual value of the other type of label\n",
    "# return X_left: the feature matrix X of the subset of data with X[split] < thre, shape = [nl, p]\n",
    "# return y_left: the lable vector y of the subset of data with X[split] < thre, shape = [nl, 1]\n",
    "# return y_left_0: the label vector y of the subset of data with X[split] < thre and y == 0, shape = [nl0, 1]\n",
    "# return y_left_1: the label vector y of the subset of data with X[split] < thre and y == 1, shape = [nl1, 1]\n",
    "# return X_right: the feature matrix X of the subset of data with X[split] >= thre, shape = [nr, p]\n",
    "# return y_right: the lable vector y of the subset of data with X[split] >= thre, shape = [nr, 1]\n",
    "# return y_right_0: the label vector y of the subset of data with X[split] >= thre and y == 0, shape = [nr0, 1]\n",
    "# return y_right_1: the label vector y of the subset of data with X[split] >= thre and y == 1, shape = [nr1, 1]\n",
    "def split_binary_children(X, y, split, thre, y0 = 0, y1 = 1):\n",
    "    # left branch of the splitting node\n",
    "    X_left = X[X[:, split] < thre]\n",
    "    y_left = y[X[:, split] < thre]\n",
    "    y_left_0 = y_left[y_left == y0]\n",
    "    y_left_1 = y_left[y_left == y1]\n",
    "    # right branch of root\n",
    "    X_right = X[X[:, split] >= thre]\n",
    "    y_right = y[X[:, split] >= thre]\n",
    "    y_right_0 = y_right[y_right == y0]\n",
    "    y_right_1 = y_right[y_right == y1]\n",
    "    return X_left, y_left, y_left_0, y_left_1, X_right, y_right, y_right_0, y_right_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes gini index of a node with binary labels (0, 1)\n",
    "# parameter n0: number of data points of one category\n",
    "# parameter n1: number of data points of the other category\n",
    "# return the gini index in the node\n",
    "def gini(n0, n1):\n",
    "    n = n0 + n1\n",
    "    return 2 * n0 * n1 / n ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the split split for a binary decision stump (level = 1)\n",
    "# using gini index (= 2 * p * (1-p)) as the splitting criteria\n",
    "# parameter X: the feature matrix, shape = [n, p]\n",
    "# parameter y: the label vector, shape = [n, 1]\n",
    "# parameter best_thre: the \"preset\" best splitting threshold for the best split variable (in binary case 0.5)\n",
    "# return best: the index for the best splitting variable in X, in [0, p)\n",
    "def best_split(X, y, best_thre):\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    if p == 1: # if only 1 variable in consideration, it is the best split\n",
    "        return 0\n",
    "    best = -1\n",
    "    min_gini = 0.5\n",
    "    for j in range(0, p): # split on variable X[j] on root\n",
    "        X_left, y_left, y_left_0, y_left_1, X_right, y_right, y_right_0, y_right_1 = split_binary_children(X, y, j, best_thre)\n",
    "        # left branch of root\n",
    "        n_left = X_left.shape[0]\n",
    "        n_left_0 = y_left_0.shape[0]\n",
    "        n_left_1 = y_left_1.shape[0]\n",
    "        assert n_left == n_left_1 + n_left_0 \n",
    "        gini_left = gini(n_left_0, n_left_1)\n",
    "        # right branch of root\n",
    "        n_right = X_right.shape[0]\n",
    "        n_right_0 = y_right_0.shape[0]\n",
    "        n_right_1 = y_right_1.shape[0]\n",
    "        assert n_right == n_right_0 + n_right_1 \n",
    "        gini_right = gini(n_right_0, n_right_1)\n",
    "        # gini after split\n",
    "        assert n == n_left + n_right\n",
    "        gini_j = n_left / n * gini_left + n_right / n * gini_right\n",
    "        if gini_j < min_gini:\n",
    "            best = j\n",
    "            min_gini = gini_j\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best split variable index is 0\n",
      "The best split variable is X[1]\n"
     ]
    }
   ],
   "source": [
    "best = best_split(train_X, train_y, 0.5)\n",
    "print('The best split variable index is', best)\n",
    "print('The best split variable is X[' + str(best + 1) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relavent statistics of the decision stump are computed as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in the left child: 243\n",
      "Number of points in the left child and y = 0: 209\n",
      "Number of points in the left child and y = 1: 34\n",
      "Number of points in the right child: 257\n",
      "Number of points in the right child and y = 0: 32\n",
      "Number of points in the right child and y = 1: 225\n",
      "Gini index before split: 0.499608\n",
      "Gini index in the left child: 0.24068146793341125\n",
      "Gini index in the right child: 0.21801995488198156\n"
     ]
    }
   ],
   "source": [
    "X_left, y_left, y_left_0, y_left_1, X_right, y_right, y_right_0, y_right_1 = split_binary_children(train_X, train_y, best, 0.5)\n",
    "print('Number of points in the left child:', X_left.shape[0])\n",
    "print('Number of points in the left child and y = 0:', y_left_0.shape[0])\n",
    "print('Number of points in the left child and y = 1:', y_left_1.shape[0])\n",
    "print('Number of points in the right child:', X_right.shape[0])\n",
    "print('Number of points in the right child and y = 0:', y_right_0.shape[0])\n",
    "print('Number of points in the right child and y = 1:', y_right_1.shape[0])\n",
    "gini_root = gini(y_left.shape[0], y_right.shape[0])\n",
    "gini_left_0 = gini(y_left_0.shape[0], y_left_1.shape[0])\n",
    "gini_right_0 = gini(y_right_0.shape[0], y_right_1.shape[0])\n",
    "print('Gini index before split:', gini_root)\n",
    "print('Gini index in the left child:', gini_left_0)\n",
    "print('Gini index in the right child:', gini_right_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently we could use Sklearn package to compute the best decision stump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best split using the sklearn package, for the picture\n",
    "dt = tree.DecisionTreeClassifier(max_depth = 1)\n",
    "dt = dt.fit(train_X, train_y)\n",
    "dotfile = open('tree_best_split.dot', 'w')\n",
    "tree.export_graphviz(dt, out_file = dotfile)\n",
    "dotfile.close()\n",
    "system('dot -Tpng tree_best_split.dot -o ../hw2_answer/images/tree_best_split.png')\n",
    "system('rm tree_best_split.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2a1, decision stump based on the best surrogate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best surrogate split on the root for a given best split stump\n",
    "# parameter X: the feature matrix, shape = [n, p]\n",
    "# parameter best: the index for the best split variable in X, in [0, p)\n",
    "# parameter best_thre: the splitting threshold for the best split variable X[best]\n",
    "# parameter best_surr_thre: the \"preset\" splitting threshold for the best surrogate split variable (in binary case 0.5)\n",
    "# return best_surr: the index for the best surrogate split variable in X, in [0, p)\n",
    "def best_surrogate_split(X, best, best_thre, best_surr_thre):\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    assert best >= 0 and best < p\n",
    "    # pL and pR on the best split variable (not used)\n",
    "    pl = X[X[:, best] < best_thre] / n\n",
    "    pr = 1 - pl\n",
    "    if p == 1: # no best surrogate split variable if only 1 variable in consideration\n",
    "        return -1\n",
    "    # pLbLj + pRbRj for all other variables that are not the best split variable\n",
    "    best_surr = -1\n",
    "    best_surr_sum = 0;\n",
    "    for j in range(0, p):\n",
    "        if j == best: # the best split variable\n",
    "            continue\n",
    "        plblj = X[np.logical_and(X[:, best] < best_thre, X[:, j] < best_surr_thre)].shape[0] / n\n",
    "        prbrj = X[np.logical_and(X[:, best] >= best_thre, X[:, j] >= best_surr_thre)].shape[0] / n\n",
    "        if plblj + prbrj > best_surr_sum:\n",
    "            best_surr = j\n",
    "            best_surr_sum = plblj + prbrj\n",
    "    return best_surr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best surrogate split variable index is 1\n",
      "The best surrogate split variable is X[2]\n"
     ]
    }
   ],
   "source": [
    "best_surr = best_surrogate_split(train_X, 0, 0.5, 0.5)\n",
    "print('The best surrogate split variable index is', best_surr)\n",
    "print('The best surrogate split variable is X[' + str(best_surr + 1) + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on comparison, the best surrogate split for X1 is X2. The splitting threshold doesn't matter since X2 values are binary. Relavent statistics of the decision stump are computed as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in the left child: 246\n",
      "Number of points in the left child and y = 0: 176\n",
      "Number of points in the left child and y = 1: 70\n",
      "Number of points in the right child: 254\n",
      "Number of points in the right child and y = 0: 65\n",
      "Number of points in the right child and y = 1: 189\n",
      "Gini index before split: 0.499872\n",
      "Gini index in the left child: 0.4071650472602287\n",
      "Gini index in the right child: 0.38083576167152333\n"
     ]
    }
   ],
   "source": [
    "X_left, y_left, y_left_0, y_left_1, X_right, y_right, y_right_0, y_right_1 = split_binary_children(train_X, train_y, best_surr, 0.5)\n",
    "print('Number of points in the left child:', X_left.shape[0])\n",
    "print('Number of points in the left child and y = 0:', y_left_0.shape[0])\n",
    "print('Number of points in the left child and y = 1:', y_left_1.shape[0])\n",
    "print('Number of points in the right child:', X_right.shape[0])\n",
    "print('Number of points in the right child and y = 0:', y_right_0.shape[0])\n",
    "print('Number of points in the right child and y = 1:', y_right_1.shape[0])\n",
    "gini_root = gini(y_left.shape[0], y_right.shape[0])\n",
    "gini_left_1 = gini(y_left_0.shape[0], y_left_1.shape[0])\n",
    "gini_right_1 = gini(y_right_0.shape[0], y_right_1.shape[0])\n",
    "print('Gini index before split:', gini_root)\n",
    "print('Gini index in the left child:', gini_left_1)\n",
    "print('Gini index in the right child:', gini_right_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2a2, 2 variable importance measures of all variables of the tree based on the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2708385497750236 0.10608222981883361\n"
     ]
    }
   ],
   "source": [
    "x1_importance_2 = gini_root - 243 / 500 * gini_left_0 - 257 / 500 * gini_right_0\n",
    "x2_importance_3 = gini_root - 246 / 500 * gini_left_1 - 254 / 500 * gini_right_1\n",
    "print(x1_importance_2, x2_importance_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2a3, mean squares error of prediction on the test data of 2 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.27\n"
     ]
    }
   ],
   "source": [
    "# best split\n",
    "yhat_test_tree_best_split = np.ones(100)\n",
    "yhat_test_tree_best_split[test_X[:, 0] == 0] = 0\n",
    "mse_test_tree_best_split = np.sum((yhat_test_tree_best_split - test_y) ** 2) / 100\n",
    "print(mse_test_tree_best_split)\n",
    "# best surrogate split\n",
    "yhat_test_tree_best_sur_split = np.ones(100)\n",
    "yhat_test_tree_best_sur_split[test_X[:, 1] == 0] = 0\n",
    "mse_test_tree_best_sur_split = np.sum((yhat_test_tree_best_sur_split - test_y) ** 2) / 100\n",
    "print(mse_test_tree_best_sur_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2b1 grow random forest of decision stumps\n",
    "\n",
    "M = 1000 stumps\n",
    "\n",
    "B = 0.8 * n bootstrap training samples\n",
    "\n",
    "K = 1, 2, 3, 4, 5 random seleted variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter M: number of stumps to generate in the forest\n",
    "# parameter b: bootstrap resample percentage\n",
    "# parameter K: number of randomly selected features in each stump\n",
    "def random_forest(X, y, M, b, K):\n",
    "    best_dic = {}\n",
    "    best_surr_dic = {}\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    n = X.shape[0]\n",
    "    B = int(round(b * n))\n",
    "    p = X.shape[1]\n",
    "    assert K <= p\n",
    "    for j in range(p):\n",
    "        best_dic[j] = 0\n",
    "        best_surr_dic[j] = 0\n",
    "    for m in range(M): # tree\n",
    "        n_idx = np.random.choice(n, B, replace = False)\n",
    "        feature_idx = np.random.choice(p, K, replace = False) # indices for selected features\n",
    "        y_sample = y[n_idx, :]\n",
    "        X_sample = X[n_idx, :]\n",
    "        X_sample = X_sample[:, feature_idx]\n",
    "        best_idx = best_split(X_sample.reshape(B, K), y_sample.reshape(B, 1), 0.5) # the \"false\" best split variable index in feature_idx\n",
    "        best_surr_idx = best_surrogate_split(X_sample.reshape(B, K), best_idx, 0.5, 0.5) # the \"false\" best surrogate variable index in feature_idx\n",
    "        # update counter        \n",
    "        best = feature_idx[best_idx] # the \"real\" best split variable index in X\n",
    "        best_dic[best] = best_dic[best] + 1\n",
    "        if best_surr_idx != -1: # the best surrogate splitting variable doesn't exist (K = 1)\n",
    "            best_surr = feature_idx[best_surr_idx] # the \"real\" best surrogate variable index in X\n",
    "            best_surr_dic[best_surr] = best_surr_dic[best_surr] + 1\n",
    "    return best_dic, best_surr_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2b1\n",
    "\n",
    "For each K = 1, 2, 3, 4, 5:\n",
    "\n",
    "    how many times each variable is the best split\n",
    "    \n",
    "    how many times each variable is the best surrogate split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1:\n",
      "The map for best split variable is: {0: 176, 1: 198, 2: 209, 3: 203, 4: 214}\n",
      "The map for best surrogate split variable is: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
      "====================\n",
      "K = 2:\n",
      "The map for best split variable is: {0: 424, 1: 282, 2: 113, 3: 107, 4: 74}\n",
      "The map for best surrogate split variable is: {0: 0, 1: 106, 2: 293, 3: 278, 4: 323}\n",
      "====================\n",
      "K = 3:\n",
      "The map for best split variable is: {0: 599, 1: 283, 2: 44, 3: 53, 4: 21}\n",
      "The map for best surrogate split variable is: {0: 0, 1: 300, 2: 264, 3: 141, 4: 295}\n",
      "====================\n",
      "K = 4:\n",
      "The map for best split variable is: {0: 806, 1: 194, 2: 0, 3: 0, 4: 0}\n",
      "The map for best surrogate split variable is: {0: 0, 1: 617, 2: 145, 3: 22, 4: 216}\n",
      "====================\n",
      "K = 5:\n",
      "The map for best split variable is: {0: 1000, 1: 0, 2: 0, 3: 0, 4: 0}\n",
      "The map for best surrogate split variable is: {0: 0, 1: 1000, 2: 0, 3: 0, 4: 0}\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "best_dic_list = []\n",
    "best_surr_dic_list = []\n",
    "for k in range(1, 6):\n",
    "    best_dic, best_surr_dic = random_forest(train_X, train_y.reshape((500, 1)), 1000, 0.8, k)\n",
    "    best_dic_list.append(best_dic)\n",
    "    best_surr_dic_list.append(best_surr_dic)\n",
    "    print('K = ' + str(k) + ':')\n",
    "    print('The map for best split variable is:', best_dic)\n",
    "    print('The map for best surrogate split variable is:', best_surr_dic)\n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## q2b2\n",
    "\n",
    "For each k = 1, 2, 3, 4, 5:\n",
    "\n",
    "    compute 2 variable importance measures for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 0.27057454977502365, 1: 0.1060822298188336, 2: -0.012867532139093751, 3: 0.0005550311283423759, 4: -0.008483785080855455}, {0: 0.27057454977502365, 1: 0.10608222981883361, 2: -0.01286753213909375, 3: 0.0005550311283423759, 4: -0.008483785080855455}, {0: 0.27057454977502365, 1: 0.10608222981883361, 2: -0.012867532139093751, 3: 0.0005550311283423759, 4: -0.008483785080855455}, {0: 0.27057454977502365, 1: 0.10608222981883361, 2: -1, 3: -1, 4: -1}, {0: 0.27057454977502365, 1: -1, 2: -1, 3: -1, 4: -1}]\n"
     ]
    }
   ],
   "source": [
    "# equation 5\n",
    "# imp(Xj) = sum(imp(Xj) in tree m) / M\n",
    "imp_dic_list = [] # a list of variable importance dictionary for each k\n",
    "for k in range(1, 6):\n",
    "    imp_dic = {} # a dictionary of variable importance for each variable\n",
    "    best_dic = best_dic_list[k - 1]\n",
    "    n = train_X.shape[0]\n",
    "    p = train_X.shape[1]\n",
    "    for j in range(p): # compute imp(Xj) = delta(gini index) for each variable\n",
    "        if best_dic[j] == 0: # the variable j is not used in any tree for this k, then no importance to report\n",
    "            imp_j = -1\n",
    "        else:\n",
    "            X_left, y_left, y_left_0, y_left_1, X_right, y_right, y_right_0, y_right_1 = split_binary_children(train_X, train_y, j, 0.5)\n",
    "            gini_root = gini(y_left.shape[0], y_right.shape[0])\n",
    "            gini_left = gini(y_left_0.shape[0], y_left_1.shape[0])\n",
    "            gini_right = gini(y_right_0.shape[0], y_right_1.shape[0])\n",
    "            delta_gini = gini_root - y_left.shape[0] / n * gini_left - y_right.shape[0] / n * gini_right\n",
    "            imp_j = best_dic[j] * delta_gini / best_dic[j]\n",
    "        imp_dic[j] = imp_j\n",
    "    imp_dic_list.append(imp_dic)\n",
    "print(imp_dic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equation 6\n",
    "# imp(Xj) = sum(error(Xoob, perm) - error(Xoob) in tree m) / M\n",
    "imp_dic_list_6 = []\n",
    "for k in range(1, 6):\n",
    "    imp_dic_6 = {}\n",
    "    best_dic = best_dic_list[k - 1] # best split variable index and time of occurance\n",
    "    n = train_X.shape[0]\n",
    "    p = train_X.shape[1]\n",
    "    for j in range(p):\n",
    "        if best_dic[j] == 0: # the variable j is not used in any tree for this k, then no importance to report\n",
    "            imp_j = -1\n",
    "        else:\n",
    "            yhat = np.ones(100) # TODO out-of-bag sample\n",
    "            yhat[train_X[:, j] == 0] = 0\n",
    "            mse = np.sum((yhat - train_y) ** 2) / 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
