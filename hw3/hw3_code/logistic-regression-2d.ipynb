{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing logistic regression from scratch\n",
    "\n",
    "The goal of this notebook is to implement your own logistic regression classifier. You will:\n",
    "\n",
    " * Extract features from Amazon product reviews.\n",
    " * Implement the link function for logistic regression.\n",
    " * Write a function to compute the derivative of the log likelihood function with respect to a single coefficient.\n",
    " * Implement gradient descent/ascent.\n",
    " * Given a set of coefficients, predict whether it has high rating.\n",
    " * Compute classification accuracy for the logistic regression model.\n",
    " \n",
    "Let's get started! \n",
    "\n",
    "*This file is adapted from course material by Carlos Guestrin and Emily Fox. The data is subsetted from the Amazon review data available at http://jmcauley.ucsd.edu/data/amazon/. *\n",
    "    \n",
    "## Import packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## please make sure that the packages are updated to the newest version. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we will use a subset of the UCI *Weight Lifting Exercises monitored with Inertial Measurement Units Data Set* contributed by *Wallace Ugulino* and *Eduardo Velloso*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One column of this dataset is 'rating', ranging from 1 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us quickly explore more of this dataset.  The 'name' column indicates the name of the product.  Here we list the first 10 products in the dataset.  We then count the number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Britax Marathon Convertible Car Seat, Granite\n",
       "1                          PRIMO EuroBath, Pearl White\n",
       "2              Jeep Shopping Cart and High Chair Cover\n",
       "3                  Pearhead Wood Bank, Memorybox White\n",
       "4             The Juppy Baby Walker (Pink-Full Lining)\n",
       "5                    The First Years Car Rear Sunshade\n",
       "6    Vulli Products - Sophie The Giraffe Teething R...\n",
       "7                Cuisinart CS-6 Baby Bottle Sterilizer\n",
       "8          Graco Sarah Classic Convertible Crib, White\n",
       "9    Cosco - Scenera Convertible Car Seat, Realtree...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(10)['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of high_rating (5-star) reviews = 25693\n",
      "# of low_rating (not 5-star) reviews = 24473\n"
     ]
    }
   ],
   "source": [
    "print '# of high_rating (5-star) reviews =', len(products[products['rating']>=5])\n",
    "print '# of low_rating (not 5-star) reviews =', len(products[products['rating']<5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-label the reviews by whether it is a 5-star review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['high_rating'] = (products['rating'] > 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply text cleaning on the review data\n",
    "\n",
    "In this section, we will perform some simple feature cleaning using Pandas and Numpy. Here we compiled a list of 193 most frequent words (important words) into a JSON file. \n",
    "\n",
    "Now, we will load these words from this JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('important_words.json', 'r') as f: # Reads the list of most frequent words\n",
    "    important_words = json.load(f)\n",
    "important_words = [str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Compute word counts (only for **important_words**)\n",
    "\n",
    "We start with *Step 1* which can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.replace(string.punctuation, ' ') \n",
    "\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed with *Step 2*. For each word in **important_words**, we compute a count for the number of times the word occurs in the review. We will store this count in a separate column (one for each word). The result of this feature processing is a single column for each word in **important_words** which keeps a count of the number of times the respective word occurs in the review text.\n",
    "\n",
    "\n",
    "**Note:** There are several ways of doing this. In this assignment, we use the built-in *count* function for Python lists. Each review string is first split into individual words and the number of occurances of a given word is counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame **products** now contains one column for each of the 193 **important_words**. As an example, the column **perfect** contains a count of the number of times the word **perfect** occurs in each of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write some code to compute the number of product reviews that contain the word **perfect**.\n",
    "\n",
    "**Hint**: \n",
    "* First create a column called `contains_perfect` which is set to 1 if the count of the word **perfect** (stored in column **perfect**) is >= 1.\n",
    "* Sum the number of 1s in the column `contains_perfect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "products['contains_perfect'] = products['perfect'].apply(lambda x: 1 if x>=1 else 0)\n",
    "count = np.sum(list(products['contains_perfect']))\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we drop some raw columns to save memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## please update pandas to the newest version in order to execute the following line\n",
    "\n",
    "products = products.drop(columns = ['name', 'review', 'review_clean', 'rating']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DataFrame to NumPy array\n",
    "\n",
    "As you have seen, NumPy is a powerful library for doing matrix manipulation. Let us convert our data to matrices and then implement our algorithms with matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide you with a function that extracts columns from an DataFrame and converts them into a NumPy array. Two arrays are returned: one representing features and another representing class labels. Note that the feature matrix includes an additional column 'intercept' to take account of the intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, label):\n",
    "    dataframe['intercept'] = 1\n",
    "    features = ['intercept'] + features\n",
    "    feature_matrix = np.array(dataframe[features])\n",
    "    label_array = np.array(dataframe[label])\n",
    "    return(feature_matrix, label_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us convert the data into NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning: This may take a few minutes...\n",
    "feature_matrix, high_rating = get_numpy_data(products, important_words, 'high_rating') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see what the **high_rating** column looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating conditional probability with logistic sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from lecture that the predicted conditional probablity (of a positive label) is given by:\n",
    "$$\n",
    "P(y^{(i)} = 1 | \\mathbf{x}^{(i)},\\mathbf{w}) = \\sigma( \\mathbf{w}^T \\mathbf{x}^{(i)} ) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T \\mathbf{x}^{(i)})},\n",
    "$$\n",
    "\n",
    "where the feature vector $\\mathbf{x}^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x^(i), w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "    \n",
    "    # Compute the conditional probability\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "\n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside**. How the sigmoid function works with matrix algebra\n",
    "\n",
    "Since the word counts are stored as columns in **feature_matrix**, each $i$-th row of the matrix corresponds to the feature vector $\\mathbf{x}^{(i)}$:\n",
    "$$\n",
    "[\\text{feature_matrix}] =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "(\\mathbf{x}^{(1)})^T \\\\\n",
    "(\\mathbf{x}^{(2)})^T \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{x}^{(N)})^T\n",
    "\\end{array}\n",
    "\\right] =\n",
    "\\left[\n",
    "\\begin{array}{cccc}\n",
    "\\mathbf{x}^{(1)}_1 & \\mathbf{x}^{(1)}_2 & \\cdots & \\mathbf{x}^{(1)}_D \\\\\n",
    "\\mathbf{x}^{(2)}_1 & \\mathbf{x}^{(2)}_2 & \\cdots & \\mathbf{x}^{(2)}_D \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\mathbf{x}^{(N)}_1 & \\mathbf{x}^{(N)}_2 & \\cdots & \\mathbf{x}^{(N)}_D\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "By the rules of matrix multiplication, the score vector containing elements $\\mathbf{w}^T h(\\mathbf{x}_i)$ is obtained by multiplying **feature_matrix** and the coefficient vector $\\mathbf{w}$.\n",
    "$$\n",
    "[\\text{score}] =\n",
    "[\\text{feature_matrix}]\\mathbf{w} =\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "(\\mathbf{x}^{(1)})^T \\\\\n",
    "(\\mathbf{x}^{(2)})^T \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{x}^{(N)})^T\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\mathbf{w}\n",
    "= \\left[\n",
    "\\begin{array}{c}\n",
    "(\\mathbf{x}^{(1)})^T \\mathbf{w} \\\\\n",
    "(\\mathbf{x}^{(2)})^T \\mathbf{w} \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{x}^{(N)})^T \\mathbf{w}\n",
    "\\end{array}\n",
    "\\right]\n",
    "= \\left[\n",
    "\\begin{array}{c}\n",
    "\\mathbf{w}^T \\mathbf{x}^{(1)} \\\\\n",
    "\\mathbf{w}^T \\mathbf{x}^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{w}^T \\mathbf{x}^{(1)}\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**\n",
    "\n",
    "Just to make sure you are on the right track, we have provided a few examples. If your `predict_probability` function is implemented correctly, then the outputs will match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "print correct_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [0.98201379 0.26894142]\n",
      "output of predict_probability = [0.9820137900379085, 0.2689414213699951]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_predictions           =', correct_predictions\n",
    "print 'output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute derivative of log likelihood (negation of the cross entropy loss) with respect to a single coefficient\n",
    "\n",
    "In part (b), we have shown:\n",
    "$$\\frac{\\partial \\ell\\ell(\\mathbf{w})}{\\partial \\mathbf{w}_j} = \\sum_{i=1}^N \\mathbf{x}^{(i)}_j \\left( y^{(i)} - \\sigma( \\mathbf{w}^\\top \\mathbf{x}^{(i)} ) \\right)\n",
    "$$\n",
    "where $\\ell\\ell$ stands for log-likelihood.\n",
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $\\mathbf{w}_j$. The function accepts two arguments:\n",
    "* `errors` vector containing $\\left( y^{(i)} - \\sigma( \\mathbf{w}^\\top \\mathbf{x}^{(i)} ) \\right)$ for all $i$.\n",
    "* `feature` vector containing $\\mathbf{x}^{(i)}$  for all $i$. \n",
    "\n",
    "Complete the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(errors, feature)\n",
    "    \n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to its numerical stability, we will use the log likelihood instead of the likelihood to assess the algorithm.\n",
    "\n",
    "Recall: the log likelihood is computed using the following formula:\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( y^{(i)} \\ln\\left( \\sigma(\\mathbf{w}^T \\mathbf{x}^{(i)} )\\right) + \\left(1 -y^{(i)} \\right) \\ln\\left( 1 - \\sigma(\\mathbf{w}^T \\mathbf{x}^{(i)} )\\right) \\Big) $$\n",
    "\n",
    "We provide a function to compute the log likelihood for the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, high_rating, coefficients):\n",
    "        \n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    sig = 1./(1. + np.exp(-scores) )\n",
    "    \n",
    "    ## YOUR CODE HERE, do check overflow/underflow problem.\n",
    "    ...\n",
    "    \n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**\n",
    "\n",
    "Just to make sure we are on the same page, run the following code block and check that the outputs match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -4.331411615436032\n",
      "output of compute_log_likelihood = -4.331411615436033\n"
     ]
    }
   ],
   "source": [
    "# here uses another way to compute log-likelihood. Don't worry about it too much.\n",
    "\n",
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,0.,0]])\n",
    "dummy_coefficients = np.array([1., 3., -1])\n",
    "dummy_high_rating = np.array([0, 1])\n",
    "\n",
    "correct_indicators  = np.array( [ 0==+1,                                       1==+1 ] )\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),                     1.*1. + (0.)*3. + (0.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],  (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])),      np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0], correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_log_likelihood           =', correct_ll\n",
    "print 'output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix, dummy_high_rating, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking gradient steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement our own logistic regression. All we have to do is to write a gradient ascent function that takes gradient steps towards the optimum. \n",
    "\n",
    "Complete the following function to solve the logistic regression model using gradient ascent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def logistic_regression(feature_matrix, high_rating, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in xrange(max_iter):\n",
    "\n",
    "        # Predict P(y^(i) = +1|x^(i),w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        ...\n",
    "                \n",
    "        # Compute the errors as y - predictions\n",
    "        errors = high_rating - predictions\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            \n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n",
    "            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            # YOUR CODE HERE\n",
    "            ...\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            ## YOUR CODE HERE\n",
    "            ...\n",
    "        \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, high_rating, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us run the logistic regression solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -34770.14654431\n",
      "iteration   1: log likelihood of observed labels = -34767.87459771\n",
      "iteration   2: log likelihood of observed labels = -34765.60560727\n",
      "iteration   3: log likelihood of observed labels = -34763.33956017\n",
      "iteration   4: log likelihood of observed labels = -34761.07644369\n",
      "iteration   5: log likelihood of observed labels = -34758.81624520\n",
      "iteration   6: log likelihood of observed labels = -34756.55895218\n",
      "iteration   7: log likelihood of observed labels = -34754.30455219\n",
      "iteration   8: log likelihood of observed labels = -34752.05303288\n",
      "iteration   9: log likelihood of observed labels = -34749.80438201\n",
      "iteration  10: log likelihood of observed labels = -34747.55858740\n",
      "iteration  11: log likelihood of observed labels = -34745.31563700\n",
      "iteration  12: log likelihood of observed labels = -34743.07551881\n",
      "iteration  13: log likelihood of observed labels = -34740.83822096\n",
      "iteration  14: log likelihood of observed labels = -34738.60373163\n",
      "iteration  15: log likelihood of observed labels = -34736.37203911\n",
      "iteration  20: log likelihood of observed labels = -34725.25512468\n",
      "iteration  30: log likelihood of observed labels = -34703.22456228\n",
      "iteration  40: log likelihood of observed labels = -34681.45613564\n",
      "iteration  50: log likelihood of observed labels = -34659.93984484\n",
      "iteration  60: log likelihood of observed labels = -34638.66639484\n",
      "iteration  70: log likelihood of observed labels = -34617.62714006\n",
      "iteration  80: log likelihood of observed labels = -34596.81403315\n",
      "iteration  90: log likelihood of observed labels = -34576.21957777\n",
      "iteration 100: log likelihood of observed labels = -34555.83678487\n",
      "iteration 200: log likelihood of observed labels = -34362.40365516\n",
      "iteration 300: log likelihood of observed labels = -34185.00552786\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, high_rating, initial_coefficients=np.zeros(194),\n",
    "                                   step_size=1e-7, max_iter=301)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting high_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from lecture that class predictions for a data point $\\mathbf{x}^{(i)}$ can be computed from the coefficients $\\mathbf{w}$ using the following formula:\n",
    "$$\n",
    "\\hat{y}^{(i)} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & \\mathbf{w}^T \\mathbf{x}^{(i)} > 0 \\\\\n",
    "      0 & \\mathbf{w}^T \\mathbf{x}^{(i)} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Now, we will write some code to compute class predictions. We will do this in two steps:\n",
    "* **Step 1**: First compute the **scores** using **feature_matrix** and **coefficients** using a dot product.\n",
    "* **Step 2**: Using the formula above, compute the class predictions from the scores.\n",
    "\n",
    "Step 1 can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the scores as a dot product between feature_matrix and coefficients.\n",
    "scores = np.dot(feature_matrix, coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, complete the following code block for **Step 2** to compute the class predictions using the **scores** obtained above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26998\n"
     ]
    }
   ],
   "source": [
    "class_pred = scores>0\n",
    "print list(class_pred).count(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question** i: How many reviews were predicted to have high rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "We will now measure the classification accuracy of the model. Recall from the lecture that the classification accuracy can be computed as follows:\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "Complete the following code block to compute the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "# Reviews   correctly classified = 33089\n",
      "# Reviews incorrectly classified = 17077\n",
      "# Reviews total                  = 50166\n",
      "-----------------------------------------------------\n",
      "Accuracy = 0.66\n"
     ]
    }
   ],
   "source": [
    "... # YOUR CODE HERE\n",
    "... # YOUR CODE HERE\n",
    "print \"-----------------------------------------------------\"\n",
    "print '# Reviews   correctly classified =', len(products) - num_mistakes\n",
    "print '# Reviews incorrectly classified =', num_mistakes\n",
    "print '# Reviews total                  =', len(products)\n",
    "print \"-----------------------------------------------------\"\n",
    "print 'Accuracy = %.2f' % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** ii: What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words contribute most to high ratings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do inspect the importance of the words, we will first do the following:\n",
    "* Treat each coefficient as a tuple, i.e. (**word**, **coefficient_value**).\n",
    "* Sort all the (**word**, **coefficient_value**) tuples by **coefficient_value** in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **word_coefficient_tuples** contains a sorted list of (**word**, **coefficient_value**) tuples. The first 10 elements in this list correspond to the words that are most positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ten \"most positive\" words\n",
    "\n",
    "Now, we compute the 10 words that have the most positive coefficient values. These words are associated with high ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 0.05417175110031363),\n",
       " ('loves', 0.03341634129158078),\n",
       " ('easy', 0.033389137480016776),\n",
       " ('great', 0.025580515307137473),\n",
       " ('perfect', 0.018573255618985464),\n",
       " ('recommend', 0.018198089912211276),\n",
       " ('baby', 0.015214316424304965),\n",
       " ('best', 0.012004878798543237),\n",
       " ('daughter', 0.009724230930764757),\n",
       " ('old', 0.009607388050573889),\n",
       " ('fits', 0.00917736061196277),\n",
       " ('also', 0.009096143871771316),\n",
       " ('soft', 0.008943944922918834),\n",
       " ('happy', 0.00719076203015758),\n",
       " ('every', 0.006683151200866261),\n",
       " ('well', 0.00624658635328378),\n",
       " ('without', 0.0059343223690781904),\n",
       " ('comfortable', 0.005554796613533446),\n",
       " ('son', 0.00487337540548808),\n",
       " ('play', 0.004711611981100413),\n",
       " ('room', 0.004500995877516566),\n",
       " ('diaper', 0.004107433778957112),\n",
       " ('worth', 0.003944765282505371),\n",
       " ('many', 0.003736816435735063),\n",
       " ('months', 0.0037237525514986027),\n",
       " ('car', 0.003720454971433458),\n",
       " ('kids', 0.003277811584301806),\n",
       " ('clean', 0.003201195805194925),\n",
       " ('little', 0.0031799699580543875),\n",
       " ('night', 0.003082072689961903),\n",
       " ('year', 0.0030409244938375043),\n",
       " ('us', 0.00240012720435848),\n",
       " ('easily', 0.002275536838470771),\n",
       " ('crib', 0.0021403384334870296),\n",
       " ('set', 0.0017015566795742273),\n",
       " ('size', 0.001537204592709637),\n",
       " ('looking', 0.0014303982763842643),\n",
       " ('purchased', 0.0011362063610430512),\n",
       " ('day', 0.0010736403038844762),\n",
       " ('bottles', 0.0010670141788825323),\n",
       " ('babies', 0.0009739884494686841),\n",
       " ('works', 0.0008499924398035715),\n",
       " ('new', 0.0006104281238760826),\n",
       " ('purchase', 0.0004958060797486093),\n",
       " ('take', 0.00044283698372326637),\n",
       " ('keep', 0.00041204136630319696),\n",
       " ('makes', 0.0003965355749988251),\n",
       " ('pump', 0.00027290779423743815),\n",
       " ('won', 5.269383408000706e-05),\n",
       " ('looks', -0.00010166095079313999),\n",
       " ('month', -0.0001420435446971684),\n",
       " ('using', -0.00023744254385492467),\n",
       " ('almost', -0.0002819562130815542),\n",
       " ('nice', -0.00035969976305044363),\n",
       " ('enough', -0.0003650664436197262),\n",
       " ('lot', -0.000480089333678729),\n",
       " ('right', -0.0005102686425371165),\n",
       " ('buying', -0.0005306286705218895),\n",
       " ('second', -0.0006345067026696038),\n",
       " ('since', -0.0006836343988632529),\n",
       " ('amazon', -0.0006916791150120702),\n",
       " ('go', -0.000777273175159525),\n",
       " ('bought', -0.0007817409074797156),\n",
       " ('tub', -0.0009043998124674177),\n",
       " ('toy', -0.0009137792991781267),\n",
       " ('different', -0.0009275167226237497),\n",
       " ('able', -0.0010061385758074713),\n",
       " ('place', -0.0010864577638249042),\n",
       " ('high', -0.0011054383956069292),\n",
       " ('know', -0.0013106037922676471),\n",
       " ('went', -0.0013416058672562864),\n",
       " ('away', -0.0013800625007670839),\n",
       " ('cute', -0.0014613616614711103),\n",
       " ('around', -0.0015056513522440345),\n",
       " ('quality', -0.0017729175999331153),\n",
       " ('never', -0.0018921765262824078),\n",
       " ('weeks', -0.001911551178268126),\n",
       " ('bottle', -0.001996901058178202),\n",
       " ('used', -0.002022638470027306),\n",
       " ('found', -0.0020342536677289487),\n",
       " ('look', -0.002044993645370919),\n",
       " ('bag', -0.002231436396039103),\n",
       " ('much', -0.0022562464478958666),\n",
       " ('long', -0.0022564912405568286),\n",
       " ('times', -0.0022589706405225186),\n",
       " ('getting', -0.002274170233154865),\n",
       " ('wanted', -0.0022974475056238507),\n",
       " ('made', -0.002310150151095822),\n",
       " ('started', -0.0023358631502817134),\n",
       " ('either', -0.002335906234088302),\n",
       " ('ordered', -0.0023626713599585376),\n",
       " ('came', -0.0024025700615471633),\n",
       " ('milk', -0.0024028487697902935),\n",
       " ('big', -0.0024486967957327906),\n",
       " ('price', -0.002489917253913579),\n",
       " ('together', -0.0026246955140949114),\n",
       " ('need', -0.002626046282860759),\n",
       " ('say', -0.0026323167906124687),\n",
       " ('last', -0.002857973374799263),\n",
       " ('anything', -0.0029770409991956783),\n",
       " ('first', -0.0030095962948931765),\n",
       " ('chair', -0.003027125463661526),\n",
       " ('completely', -0.003408707445391459),\n",
       " ('said', -0.00349091357912835),\n",
       " ('worked', -0.0035037623449638124),\n",
       " ('design', -0.0035383635034365985),\n",
       " ('took', -0.003568074514403945),\n",
       " ('less', -0.003708069020495429),\n",
       " ('come', -0.0038877360934522816),\n",
       " ('child', -0.003898679997335138),\n",
       " ('however', -0.0038989983652731076),\n",
       " ('actually', -0.0039023430576277038),\n",
       " ('water', -0.004006388104535227),\n",
       " ('cover', -0.004058280159362711),\n",
       " ('hold', -0.004146709927536339),\n",
       " ('head', -0.004314267427844301),\n",
       " ('another', -0.004437482575799698),\n",
       " ('one', -0.004469293296616316),\n",
       " ('find', -0.004480819165942051),\n",
       " ('still', -0.004527148336667875),\n",
       " ('gate', -0.00454927632213572),\n",
       " ('picture', -0.004575309146607963),\n",
       " ('received', -0.0046468019535556996),\n",
       " ('side', -0.004665065681902608),\n",
       " ('company', -0.004736181104253553),\n",
       " ('reviews', -0.004803903847947965),\n",
       " ('working', -0.004872506043167943),\n",
       " ('maybe', -0.004928034431266442),\n",
       " ('give', -0.005122873137586023),\n",
       " ('item', -0.005140384576579672),\n",
       " ('idea', -0.005140934620516791),\n",
       " ('instead', -0.005157113398113808),\n",
       " ('box', -0.005220327004181243),\n",
       " ('got', -0.005349711051751325),\n",
       " ('unit', -0.005411595169075356),\n",
       " ('though', -0.005414584161840412),\n",
       " ('use', -0.005508860675226684),\n",
       " ('open', -0.005547328478421602),\n",
       " ('want', -0.005613301559706751),\n",
       " ('see', -0.005658601113842783),\n",
       " ('trying', -0.0057738637548137),\n",
       " ('cheap', -0.0059026422708318765),\n",
       " ('part', -0.005914991685553965),\n",
       " ('returned', -0.005939635492584913),\n",
       " ('try', -0.005972097948533529),\n",
       " ('broke', -0.006029511290970947),\n",
       " ('stroller', -0.006074687982364392),\n",
       " ('bad', -0.0060915473748843155),\n",
       " ('tried', -0.006092921107316139),\n",
       " ('stay', -0.0062550145392366195),\n",
       " ('two', -0.006281472550694445),\n",
       " ('sure', -0.006413722740218334),\n",
       " ('going', -0.006441626199068129),\n",
       " ('piece', -0.006445490767109502),\n",
       " ('seems', -0.0064608833677325265),\n",
       " ('cup', -0.006554571937570305),\n",
       " ('fit', -0.0065722540500112335),\n",
       " ('make', -0.006736193138682181),\n",
       " ('money', -0.006823483212940696),\n",
       " ('problem', -0.006856351888789802),\n",
       " ('bottom', -0.0068888241007317936),\n",
       " ('buy', -0.007150945871608536),\n",
       " ('seat', -0.007156586875397251),\n",
       " ('put', -0.0072409968993173),\n",
       " ('small', -0.00788294172641224),\n",
       " ('waste', -0.007969925874517869),\n",
       " ('time', -0.008184776872709626),\n",
       " ('top', -0.008291950229629464),\n",
       " ('wish', -0.008431362156372118),\n",
       " ('even', -0.008908289428389721),\n",
       " ('something', -0.009277656764725747),\n",
       " ('disappointed', -0.009544242907761012),\n",
       " ('thing', -0.009991832890720904),\n",
       " ('bit', -0.010540713684068392),\n",
       " ('difficult', -0.010545157935116503),\n",
       " ('return', -0.010850300211845026),\n",
       " ('plastic', -0.010891464614575101),\n",
       " ('pretty', -0.011064655969059025),\n",
       " ('think', -0.011607416182415974),\n",
       " ('better', -0.01171893785837706),\n",
       " ('way', -0.01200636517389574),\n",
       " ('monitor', -0.01212466087136327),\n",
       " ('thought', -0.012664530663116253),\n",
       " ('good', -0.01460154255474313),\n",
       " ('really', -0.01467031645546147),\n",
       " ('hard', -0.015237868674725086),\n",
       " ('back', -0.01600909380429341),\n",
       " ('work', -0.016221373513787964),\n",
       " ('product', -0.017354095077474443),\n",
       " ('could', -0.018893796476944145),\n",
       " ('get', -0.023544894371514236),\n",
       " ('like', -0.031072720033253332),\n",
       " ('would', -0.045868342428508284)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question** iii: What are the top 3 most positively weighted words (according to our model)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
