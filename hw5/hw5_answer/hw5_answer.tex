\documentclass[paper=letter, fontsize=12pt]{article}
\usepackage{geometry}
\geometry{margin=1in}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{mathrsfs}

%opening
\title{Compsci 571 HW5}
\author{Yilin Gao (yg95)}

\begin{document}

\maketitle
\section{Hoeffding's Inequality}

\begin{enumerate}[label=(\alph*)]
	%1a
	\item 
	
	%1b
	\item
\end{enumerate}

\section{VC Dimension}

\begin{enumerate}[label=(\alph*)]
	%2a
	\item 
	The VC dimension of $\mathcal{H}_1$ is $p$, because its feature space is $p$-dimensional, and all separating hyperplanes are linear in the feature space and goes though the origin point.
	
	The VC dimension of $\mathcal{H}_2$ is $\frac{(p+2)(p+1)}{2}$, because its feature space is $\frac{(p+2)(p+1)}{2}$-dimensional, and all separating hyperplanes are linear in the feature space and goes though the origin point.
	
	%2b
	\item The approximation and estimation errors for $\mathcal{H}_1$, $\mathcal{H}_2$ and $\hat{f}_1$, $\hat{f}_2$ are depicted as following:
	
	\includegraphics[scale=0.6]{q2b.png}
	
	In the picture, $t$ stands for the global optimal function based on true risk, $f_1^*$ and $f_2^*$ stand for the optimal functions based on true risk in function classes $\mathcal{H}_1$ and $\mathcal{H}_2$ respectively, and $\hat{f}_1$ and $\hat{f}_2$ are optimal functions based on empirical risk in function classes $\mathcal{H}_1$ and $\mathcal{H}_2$ respectively.
	
	As $n$ increases, the estimation error increases because with more data we are able to estimate the model more accurately, and decrease the discrepancy between true risk and empirical risk, i.e., the estimation error. And the approximation error won't be affected significantly because the approximation error is dependent on the function class $\mathcal{H}$, but not the data.
	
	%2c
	\item One function class F such that its VC dimension is not equal to its number of parameters is the set of functions generated by the K-nearest nerighbors algorithm with $K=1$. It only has 1 parameter $K$, while its VC dimension is infinity.
\end{enumerate}

\section{Ridge Regression}

\begin{enumerate}[label=(\alph*)]
	%3a
	\item
	
	%3b
	\item
	
	%3c
	\item   
\end{enumerate}
\end{document}
